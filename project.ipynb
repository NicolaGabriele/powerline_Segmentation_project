{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolaGabriele/powerline_Segmentation_project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**IMPORT DELLE LIBRERIE E CARICAMENTO DEL DATASET**\n"
      ],
      "metadata": {
        "id": "uPlvi52C5hXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK1cN188lTCY",
        "outputId": "24178551-605d-48bd-98ac-0bd3186c8185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "k5I2awhKlnZ6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import json\n",
        "import random\n",
        "from pycocotools import mask\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "TRAIN_DIR = '/content/drive/MyDrive/trainingset' #'C:\\\\Users\\\\Nicola\\\\Documents\\\\GitHub\\\\powerline_Segmentation_project\\\\trainingset'#\n",
        "TEST_DIR = '/content/drive/MyDrive/testset' #'C:\\\\Users\\\\Nicola\\\\Documents\\\\GitHub\\\\powerline_Segmentation_project\\\\testset'#\n",
        "TRAIN_LABELS = '/content/drive/MyDrive/train.json' #'C:\\\\Users\\\\Nicola\\\\Documents\\\\GitHub\\\\powerline_Segmentation_project\\\\train.json'#\n",
        "TEST_LABELS =  '/content/drive/MyDrive/test.json' #'C:\\\\Users\\\\Nicola\\\\Documents\\\\GitHub\\\\powerline_Segmentation_project\\\\test.json'\n",
        "IM_WIDTH = 700\n",
        "IM_HEIGHT = 700"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E-B8GMC3lrq6"
      },
      "outputs": [],
      "source": [
        "def groupByImageId(jsonfile):\n",
        "  data = jsonfile['annotations']\n",
        "  labs = {}\n",
        "  for k in data:\n",
        "    if k['image_id'] in labs:\n",
        "      labs[k['image_id']].append(k)\n",
        "    else:\n",
        "      labs[k['image_id']] = [k]\n",
        "  return labs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ndYpml_vlw8E"
      },
      "outputs": [],
      "source": [
        "class PowerLineDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,img_dir,img_labels):\n",
        "    self.img_dir = img_dir\n",
        "    self.img_labels = json.load(open(img_labels))\n",
        "    self.categories = [] #lista delle etichette di classe\n",
        "    for c in self.img_labels['categories']:\n",
        "      self.categories.append(c['name'])\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels['images'][idx]['file_name'])\n",
        "    label = groupByImageId(self.img_labels)[idx]\n",
        "    image = (torchvision.io.read_image(img_path)/255)\n",
        "    return image,label\n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.img_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nPavYFFXl2FS"
      },
      "outputs": [],
      "source": [
        "#caricamento dei dataset di train e di test\n",
        "trainset = PowerLineDataset(TRAIN_DIR, TRAIN_LABELS)\n",
        "test = PowerLineDataset(TEST_DIR, TEST_LABELS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**OPERAZIONI SUI DATI: DATA AUGMENTATION**"
      ],
      "metadata": {
        "id": "benlse6i62xT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsuwaV2d6r0Z"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self, in_channels=3):\n",
        "    super(AutoEncoder,self).__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "         nn.Conv2d(in_channels, 64, kernel_size=3, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.Conv2d(64, 128, kernel_size=3, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.Conv2d(128, 256, kernel_size=3, padding = 1),\n",
        "         nn.ReLU(),\n",
        "         nn.MaxPool2d(2,stride = 2,return_indices=False))\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(256, 128, kernel_size=3, stride = 2, padding = 1, output_padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 64, kernel_size=3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, in_channels, kernel_size=3, padding = 1),\n",
        "        nn.ReLU())\n",
        "\n",
        "  def forward(self,x):\n",
        "    #x.to('cuda')\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKDxlDQ79lNg"
      },
      "outputs": [],
      "source": [
        "model = AutoEncoder()\n",
        "#model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsKV11idmA0z"
      },
      "outputs": [],
      "source": [
        "#questo metodo è preso dai notebook e va adattato al caso specifico (loss ecc...)\n",
        "#costruisco un sottodataset di 200 immagini\n",
        "#indexs = list(range(0,200))\n",
        "#trains = torch.utils.data.DataLoader(torch.utils.data.Subset(trainset,indexs), batch_size=64, shuffle=True)\n",
        "trains = torch.utils.data.DataLoader(trainset)\n",
        "criterion = torch.nn.MSELoss()\n",
        "learning_rate = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "total_step = len(trains)\n",
        "batch_size = 64\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(trains) for i in range(num_epochs + 1)]\n",
        "\n",
        "\n",
        "def train(epoch,model,criterion,optimizer,reshape=False):\n",
        "    for batch_idx, (images, labels) in enumerate(trains):\n",
        "        # Move tensors to the configured device\n",
        "        #if reshape:\n",
        "         #   images = images.reshape(-1, 28*28)\n",
        "        #images = images.to('cuda')\n",
        "        #labels = labels.to('cuda')\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, images)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if random.random() < 0.1:\n",
        "          print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch, num_epochs, batch_idx+1, total_step, loss.item()))\n",
        "        if (batch_idx+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch, num_epochs, batch_idx+1, total_step, loss.item()))\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_counter.append(\n",
        "        (batch_idx*batch_size) + ((epoch-1)*len(trains)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl-6B8ezdvky"
      },
      "outputs": [],
      "source": [
        "model = torch.load('/content/drive/MyDrive/autoencoder')\n",
        "#train(num_epochs,model,criterion, optimizer, reshape=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE5unNbvf4DP"
      },
      "outputs": [],
      "source": [
        "torch.save(model,'autoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**LOSS FUNCTIONS**"
      ],
      "metadata": {
        "id": "fOUlmpO07mta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X56SZK7Yl7u4"
      },
      "outputs": [],
      "source": [
        "def decodeSegmentationField(segmentation):\n",
        "  return mask.decode(mask.merge(mask.frPyObjects(segmentation,IM_WIDTH,IM_HEIGHT)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatLabels(labels):\n",
        "  bbox = []\n",
        "  seg = []\n",
        "  cls = []\n",
        "  for label in labels:\n",
        "    seg.append(decodeSegmentationField(label['segmentation']))\n",
        "    bbox.append(label['bbox'])\n",
        "    cls.append(label['category_id'])\n",
        "  return {\n",
        "      'id': label['id'],\n",
        "      'masks':torch.Tensor(seg),\n",
        "      'labels':torch.Tensor(cls),\n",
        "      'boxes':torch.Tensor(bbox)\n",
        "  }"
      ],
      "metadata": {
        "id": "cXTtmxRltmm4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLossFunction(nn.Module):\n",
        "  def __init__(self, cls_loss, bb_loss, seg_loss, cls_weight, bb_weight, seg_weight):\n",
        "    super(CustomLossFunction, self).__init__()\n",
        "    self.cls_loss = cls_loss\n",
        "    self.bb_loss = bb_loss\n",
        "    self.seg_loss = seg_loss\n",
        "    self.cls_weight = cls_weight\n",
        "    self.bb_weight = bb_weight\n",
        "    self.seg_weight = seg_weight\n",
        "  def forward(self,predictions, targets):\n",
        "    prediction = predictions[0]\n",
        "    formatted_targets = formatLabels(targets)\n",
        "    #loss di classificazione\n",
        "    #scores di classificazione: uno per ogni oggetto predetto\n",
        "    targets_cls = formatted_targets['labels']\n",
        "    pred_cls = prediction['scores']\n",
        "    loss_cls = self.cls_loss(pred_cls,targets_cls)\n",
        "    #loss di bbox\n",
        "    targets_bbox = formatted_targets['boxes']\n",
        "    pred_bbox = prediction['boxes']\n",
        "    loss_bbox = self.bb_loss(pred_bbox,targets_bbox)\n",
        "    #loss per le maschere: sigmoide su tutti i pixel e poi cross entropy\n",
        "    targets_masks = formatted_targets['masks']\n",
        "    pred_masks = prediction['masks']\n",
        "    loss_masks = self.seg_loss(pred_masks,targets_masks)\n",
        "\n",
        "    return self.cls_weight*loss_cls + self.bb_weight*loss_bbox + self.seg_weight*loss_masks"
      ],
      "metadata": {
        "id": "gBLzLAje8GPd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0]['labels']"
      ],
      "metadata": {
        "id": "a0wo8BZJwyBy",
        "outputId": "ad2da040-3597-4e5f-ccda-e84c9312028a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([25])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TEST DI UN MODELLO PREADDESTRATO: MASK R-CNN**"
      ],
      "metadata": {
        "id": "1xqBHACL7Pmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KbbHfR2pTSNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68746ba-a958-46b1-8242-f76ff8b7e245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
            "100%|██████████| 170M/170M [00:01<00:00, 120MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_features_box = model.roi_heads.box_predictor.cls_score.in_features\n",
        "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "\n",
        "# Get the numbner of output channels for the Mask Predictor\n",
        "dim_reduced = model.roi_heads.mask_predictor.conv5_mask.out_channels\n",
        "\n",
        "# Replace the box predictor\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_channels=in_features_box, num_classes=4)\n",
        "\n",
        "# Replace the mask predictor\n",
        "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_channels=in_features_mask, dim_reduced=dim_reduced, num_classes=4)"
      ],
      "metadata": {
        "id": "EKT2pH78mXeD"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "3S6gc70uUA9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "244f6d0c-31af-4c79-d8eb-c3cc3afc4e4e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-d9ab38ddf58e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Screenshot 2023-12-03 151743.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                         torch._assert(\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "x=torchvision.io.read_image('/content/Screenshot 2023-12-03 151743.jpg')/255\n",
        "predictions = model(trainset[1][0], formatLabels(trainset[1][1]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formatLabels(trainset[1][1])"
      ],
      "metadata": {
        "id": "tUHZrXHrs949",
        "outputId": "51c505a8-fc78-418d-9db9-e39f746db777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 18,\n",
              " 'masks': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
              " 'labels': tensor([2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " 'boxes': tensor([[239., 145., 273., 500.],\n",
              "         [420.,   0.,  75., 292.],\n",
              "         [349.,   0.,  20., 242.],\n",
              "         [251.,   0.,  29., 292.],\n",
              "         [415.,   1.,  33., 138.],\n",
              "         [579.,   0., 119., 255.],\n",
              "         [593.,   0., 106., 209.],\n",
              "         [286., 184.,  14., 514.],\n",
              "         [222., 321.,  28., 378.],\n",
              "         [455., 177.,  95., 522.],\n",
              "         [496., 300.,  76., 399.],\n",
              "         [373., 313.,  25., 386.],\n",
              "         [512.,   0., 187., 527.],\n",
              "         [ 31.,   0., 174., 699.]])}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}