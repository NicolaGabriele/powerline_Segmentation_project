{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NicolaGabriele/powerline_Segmentation_project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MK1cN188lTCY",
    "outputId": "3146e91e-f36f-4d14-ccbb-b1702b771376"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k5I2awhKlnZ6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import json\n",
    "import random\n",
    "from pycocotools import mask\n",
    "TRAIN_DIR = 'C:\\\\Users\\\\Nicola\\\\Documents\\\\GitHub\\\\powerline_Segmentation_project\\\\trainingset'#'/content/drive/MyDrive/trainingset'\n",
    "TEST_DIR = 'C:\\\\Users\\\\Nicola\\\\Documents\\\\GitHub\\\\powerline_Segmentation_project\\\\testset'#'/content/drive/MyDrive/testset'\n",
    "TRAIN_LABELS = 'C:\\\\Users\\\\Nicola\\\\Documents\\\\GitHub\\\\powerline_Segmentation_project\\\\train.json'#'/content/drive/MyDrive/train.json'\n",
    "TEST_LABELS =  'C:\\\\Users\\\\Nicola\\\\Documents\\\\GitHub\\\\powerline_Segmentation_project\\\\test.json'#'/content/drive/MyDrive/test.json'\n",
    "IM_WIDTH = 700\n",
    "IM_HEIGHT = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E-B8GMC3lrq6"
   },
   "outputs": [],
   "source": [
    "def groupByImageId(jsonfile):\n",
    "  data = jsonfile['annotations']\n",
    "  labs = {}\n",
    "  for k in data:\n",
    "    if k['image_id'] in labs:\n",
    "      labs[k['image_id']].append(k)\n",
    "    else:\n",
    "      labs[k['image_id']] = [k]\n",
    "  return labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ndYpml_vlw8E"
   },
   "outputs": [],
   "source": [
    "class PowerLineDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,img_dir,img_labels):\n",
    "    self.img_dir = img_dir\n",
    "    self.img_labels = json.load(open(img_labels))\n",
    "    self.categories = [] #lista delle etichette di classe\n",
    "    for c in self.img_labels['categories']:\n",
    "      self.categories.append(c['name'])\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    img_path = os.path.join(self.img_dir, self.img_labels['images'][idx]['file_name'])\n",
    "    label = groupByImageId(self.img_labels)[idx]\n",
    "    image = torchvision.io.read_image(img_path)/255\n",
    "    return image,image#label\n",
    "  def __len__(self):\n",
    "    return len(os.listdir(self.img_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nPavYFFXl2FS"
   },
   "outputs": [],
   "source": [
    "#caricamento dei dataset di train e di test\n",
    "trainset = PowerLineDataset(TRAIN_DIR, TRAIN_LABELS)\n",
    "test = PowerLineDataset(TEST_DIR, TEST_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "X56SZK7Yl7u4"
   },
   "outputs": [],
   "source": [
    "def decodeSegmentationField(segmentation):\n",
    "  return mask.decode(mask.merge(mask.frPyObjects(segmentation,IM_WIDTH,IM_HEIGHT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gsuwaV2d6r0Z"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "  def __init__(self, in_channels=3):\n",
    "    super(AutoEncoder,self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding = 1)\n",
    "    self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding = 1)\n",
    "    self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding = 1)\n",
    "    self.pl = nn.MaxPool2d(2,stride = 2,return_indices=True)\n",
    "    self.us = nn.MaxUnpool2d(2,stride=2)\n",
    "    self.conv4 = nn.Conv2d(256, 128, kernel_size=3, padding = 1)\n",
    "    self.conv5 = nn.Conv2d(128, 64, kernel_size=3, padding = 1)\n",
    "    self.conv6 = nn.Conv2d(64, 3, kernel_size=3, padding = 1)\n",
    "\n",
    "  def forward(self,x):\n",
    "    #x.to('cuda')\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = F.relu(self.conv3(x))\n",
    "    x, ind = self.pl(x)\n",
    "    print('before: ',x.shape)\n",
    "    x = F.relu(self.us(x, ind))\n",
    "    print(\"after: \", x.shape)\n",
    "    x = F.relu(self.conv4(x))\n",
    "    x = F.relu(self.conv5(x))\n",
    "    x = F.relu(self.conv6(x))\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XKDxlDQ79lNg"
   },
   "outputs": [],
   "source": [
    "model = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rsKV11idmA0z"
   },
   "outputs": [],
   "source": [
    "#questo metodo Ã¨ preso dai notebook e va adattato al caso specifico (loss ecc...)\n",
    "#costruisco un sottodataset di 200 immagini\n",
    "indexs = list(range(0,200)) \n",
    "trains = torch.utils.data.DataLoader(torch.utils.data.Subset(trainset,indexs), batch_size=64, shuffle=True)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "learning_rate = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "total_step = len(trains)\n",
    "batch_size = 64\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(trains) for i in range(num_epochs + 1)]\n",
    "\n",
    "\n",
    "def train(epoch,model,criterion,optimizer,reshape=False):\n",
    "    for batch_idx, (images, labels) in enumerate(trains):\n",
    "        # Move tensors to the configured device\n",
    "        #if reshape:\n",
    "         #   images = images.reshape(-1, 28*28)\n",
    "        #images = images.to('cuda')\n",
    "        #labels = labels.to('cuda')\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if random.random() < 0.3:\n",
    "          print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch, num_epochs, batch_idx+1, total_step, loss.item()))\n",
    "        if (batch_idx+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch, num_epochs, batch_idx+1, total_step, loss.item()))\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_counter.append(\n",
    "        (batch_idx*batch_size) + ((epoch-1)*len(trains)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "Kl-6B8ezdvky",
    "outputId": "32b2e266-d230-4d1b-ba6b-eb429d85e16a"
   },
   "outputs": [],
   "source": [
    "#!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu123\n",
    "#model.to('cuda')\n",
    "train(num_epochs,model,criterion, optimizer, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "sMyw6riupSRm",
    "outputId": "3b2fc432-d27f-440e-ee94-5f9157b992c4"
   },
   "outputs": [],
   "source": [
    "im = torchvision.io.read_image(os.path.join(TRAIN_DIR,'04_585.jpg'))/255\n",
    "r = model(im)\n",
    "\n",
    "#t = r.detach().numpy().reshape((700,700,3))\n",
    "#plt.imshow(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMqDqBufVMZoAvGf8ZWiaPh",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
