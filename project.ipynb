{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsbtmeL0BcbvSOFNahM2sz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolaGabriele/powerline_Segmentation_project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK1cN188lTCY",
        "outputId": "a01795e3-4c24-474b-9752-d16f03f5d1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import json\n",
        "from pycocotools import mask\n",
        "TRAIN_DIR = '/content/drive/MyDrive/trainingset'\n",
        "TEST_DIR = '/content/drive/MyDrive/testset'\n",
        "TRAIN_LABELS = '/content/drive/MyDrive/train.json'\n",
        "TEST_LABELS =  '/content/drive/MyDrive/test.json'\n",
        "IM_WIDTH = 700\n",
        "IM_HEIGHT = 700"
      ],
      "metadata": {
        "id": "k5I2awhKlnZ6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def groupByImageId(jsonfile):\n",
        "  data = jsonfile['annotations']\n",
        "  labs = {}\n",
        "  for k in data:\n",
        "    if k['image_id'] in labs:\n",
        "      labs[k['image_id']].append(k)\n",
        "    else:\n",
        "      labs[k['image_id']] = [k]\n",
        "  return labs"
      ],
      "metadata": {
        "id": "E-B8GMC3lrq6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerLineDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,img_dir,img_labels):\n",
        "    self.img_dir = img_dir\n",
        "    self.img_labels = json.load(open(img_labels))\n",
        "    self.categories = [] #lista delle etichette di classe\n",
        "    for c in self.img_labels['categories']:\n",
        "      self.categories.append(c['name'])\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels['images'][idx]['file_name'])\n",
        "    label = groupByImageId(self.img_labels)[idx]\n",
        "    image = torchvision.io.read_image(img_path)\n",
        "    return image,label\n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.img_dir))"
      ],
      "metadata": {
        "id": "ndYpml_vlw8E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#caricamento dei dataset di train e di test\n",
        "train = PowerLineDataset(TRAIN_DIR, TRAIN_LABELS)\n",
        "test = PowerLineDataset(TEST_DIR, TEST_LABELS)"
      ],
      "metadata": {
        "id": "nPavYFFXl2FS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decodeSegmentationField(segmentation):\n",
        "  return mask.decode(mask.merge(mask.frPyObjects(segmentation,IM_WIDTH,IM_HEIGHT)))"
      ],
      "metadata": {
        "id": "X56SZK7Yl7u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#questo metodo Ã¨ preso dai notebook e va adattato al caso specifico (loss ecc...)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "learning_rate = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "total_step = len(train)\n",
        "batch_size = 64\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train) for i in range(num_epochs + 1)]\n",
        "\n",
        "def train(epoch,model,criterion,optimizer,reshape=True):\n",
        "    for batch_idx, (images, labels) in enumerate(train):\n",
        "        # Move tensors to the configured device\n",
        "        if reshape:\n",
        "            images = images.reshape(-1, 28*28)\n",
        "        #images = images.to(device)\n",
        "        #labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (batch_idx+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch, num_epochs, batch_idx+1, total_step, loss.item()))\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_counter.append(\n",
        "        (batch_idx*batch_size) + ((epoch-1)*len(train)))"
      ],
      "metadata": {
        "id": "rsKV11idmA0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}